# app_upload_fix.py
# ì‹¤í–‰: streamlit run app_upload_fix.py
# í•„ìš”: pip install streamlit pandas openpyxl
# (.xls ì½ê¸° í•„ìš” ì‹œ) pip install "xlrd==1.2.0"

import io
import re
import json
import zipfile
from datetime import datetime
from typing import Optional, List

import pandas as pd
import streamlit as st

st.set_page_config(page_title="í™©ì§€í›„ì˜ ë°œì£¼ ëŒ€ì‘ì „ (1â†’2)", layout="centered")

st.title("í™©ì§€í›„ì˜ ë°œì£¼ ëŒ€ì‘ì „ (1 â†’ 2)")
st.caption("ë¼ì˜¤ë¼ / ì¿ íŒ¡ / ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´(í‚¤ì›Œë“œ) / ë– ë¦¬ëª°(í‚¤ì›Œë“œ S&V ê·œì¹™) í˜•ì‹ì„ 2ë²ˆ í…œí”Œë¦¿ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. (ì „í™”ë²ˆí˜¸ 0 ë³´ì¡´)")

# -------------------------- Helpers --------------------------
def excel_col_to_index(col_letters: str) -> int:
    col_letters = str(col_letters).strip().upper()
    if not re.fullmatch(r"[A-Z]+", col_letters):
        raise ValueError(f"Invalid Excel column letters: {col_letters}")
    idx = 0
    for ch in col_letters:
        idx = idx * 26 + (ord(ch) - ord('A') + 1)
    return idx - 1  # 0-based

def index_to_excel_col(n: int) -> str:
    s = ""
    n += 1
    while n > 0:
        n, r = divmod(n - 1, 26)
        s = chr(r + 65) + s
    return s

def excel_letters(max_cols=104):
    return [index_to_excel_col(i) for i in range(max_cols)]

def read_first_sheet_template(file) -> pd.DataFrame:
    """í…œí”Œë¦¿(2.xlsx)ì€ ì¼ë°˜ì ìœ¼ë¡œ ì½ê¸°"""
    return pd.read_excel(file, sheet_name=0, header=0, engine="openpyxl")

def read_first_sheet_source_as_text(file) -> pd.DataFrame:
    """ì†ŒìŠ¤ëŠ” ì „ ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ì½ì–´ ì „í™”ë²ˆí˜¸ ì• 0 ë³´ì¡´"""
    return pd.read_excel(
        file,
        sheet_name=0,
        header=0,
        engine="openpyxl",
        dtype=str,
        keep_default_na=False,
    )

def ensure_mapping_initialized(template_columns, default_mapping):
    m = st.session_state.get("mapping")
    if not isinstance(m, dict):
        m = {}
    synced = {k: str(v).upper() for k, v in m.items() if k in template_columns and v}
    for k in template_columns:
        if k not in synced and k in default_mapping:
            synced[k] = default_mapping[k]
    st.session_state["mapping"] = synced
    return st.session_state["mapping"]

def norm_header(s: str) -> str:
    return re.sub(r"[\s\(\)\[\]{}:ï¼š/\\\-]", "", str(s).strip().lower())

# â˜… CSVì—ì„œ Excelì´ ìˆ«ìë¡œ ì˜¤ì¸í•˜ì§€ ì•Šë„ë¡ í…ìŠ¤íŠ¸ ë³´í˜¸
def _guard_excel_text(s: str) -> str:
    """
    Excelì´ CSVë¥¼ ì—´ ë•Œ ìˆ«ìë¡œ ì˜¤ì¸í•˜ì§€ ì•Šë„ë¡ '="ê°’"' í˜•íƒœë¡œ ê°ì‹¸ê¸°.
    ì´ë¯¸ ="..." í˜•íƒœë©´ ì¤‘ë³µ ì ìš©í•˜ì§€ ì•ŠìŒ.
    """
    s = "" if s is None else str(s)
    if s == "" or s.startswith('="'):
        return s
    return f'="{s}"'

# -------------------- CSV ì¶œë ¥ ì„¤ì •(êµ¬ë¶„ì/ì¸ì½”ë”©) --------------------
CSV_SEPARATORS = {
    "ì‰¼í‘œ(,)": ",",
    "ì„¸ë¯¸ì½œë¡ (;)": ";",
    "íƒ­(\\t)": "\t",
    "íŒŒì´í”„(|)": "|",
}
CSV_ENCODINGS = {
    "UTF-8-SIG (ê¶Œì¥)": "utf-8-sig",
    "UTF-8 (BOM ì—†ìŒ)": "utf-8",
    "CP949 (ìœˆë„ìš°)": "cp949",
    "EUC-KR": "euc-kr",
}

def _get_csv_prefs():
    sep = st.session_state.get("csv_sep", ",")
    enc = st.session_state.get("csv_encoding", "utf-8-sig")
    label_sep = st.session_state.get("csv_sep_label", "ì‰¼í‘œ(,)")
    label_enc = st.session_state.get("csv_enc_label", "UTF-8-SIG (ê¶Œì¥)")
    return sep, enc, label_sep, label_enc

def download_df(
    df: pd.DataFrame,
    base_label: str,
    filename_stem: str,
    widget_key: str,
    sheet_name: Optional[str] = None,
    csv_sep_override: Optional[str] = None,      # â˜… ì¶”ê°€
    csv_encoding_override: Optional[str] = None, # â˜… ì¶”ê°€
):
    """CSV ë²„íŠ¼ì„ ë¨¼ì €, ê·¸ ë‹¤ìŒì— XLSX ë²„íŠ¼ì„ ë³´ì—¬ì£¼ëŠ” ë‹¤ìš´ë¡œë“œ ìœ„ì ¯."""
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    col_csv, col_xlsx = st.columns(2)

    # í˜„ì¬ CSV ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸° (ì˜¤ë²„ë¼ì´ë“œ ìš°ì„ )
    def _labels_from_sep(sep: str) -> str:
        return {",": "ì‰¼í‘œ(,)", ";": "ì„¸ë¯¸ì½œë¡ (;)", "\t": "íƒ­(\\t)", "|": "íŒŒì´í”„(|)"}\
               .get(sep, f"ì‚¬ìš©ì({repr(sep)})")
    def _labels_from_enc(enc: str) -> str:
        rev = {v: k for k, v in CSV_ENCODINGS.items()}
        return rev.get(enc, enc)

    default_sep, default_enc, default_sep_label, default_enc_label = _get_csv_prefs()
    csv_sep = csv_sep_override if csv_sep_override is not None else default_sep
    csv_enc = csv_encoding_override if csv_encoding_override is not None else default_enc
    label_sep = _labels_from_sep(csv_sep)
    label_enc = _labels_from_enc(csv_enc)

    # CSV ë²„íŠ¼ (ì „í™”ë²ˆí˜¸ ë³´í˜¸: ="010...")
    with col_csv:
        df_safe = df.copy()
        phone_like_cols = [c for c in df_safe.columns if re.search(r"(ì „í™”ë²ˆí˜¸|ì—°ë½ì²˜|íœ´ëŒ€í°)", str(c))]
        for c in phone_like_cols:
            df_safe[c] = df_safe[c].astype(str).map(_guard_excel_text)

        csv_str = df_safe.to_csv(index=False, sep=csv_sep, lineterminator="\n")
        csv_bytes = csv_str.encode(csv_enc, errors="replace")
        st.download_button(
            label=f"{base_label} (CSV Â· {label_sep} Â· {label_enc})",
            data=csv_bytes,
            file_name=f"{filename_stem}_{ts}.csv",
            mime="text/csv",
            key=f"btn_{widget_key}_csv",
            help="ì„ íƒí•œ(ë˜ëŠ” ê°•ì œëœ) êµ¬ë¶„ì/ì¸ì½”ë”©ìœ¼ë¡œ CSV ì €ì¥í•©ë‹ˆë‹¤.",
        )

    # XLSX ë²„íŠ¼
    with col_xlsx:
        buf = io.BytesIO()
        with pd.ExcelWriter(buf, engine="openpyxl") as writer:
            if sheet_name:
                df.to_excel(writer, index=False, sheet_name=sheet_name)
            else:
                df.to_excel(writer, index=False)
        st.download_button(
            label=f"{base_label} (XLSX)",
            data=buf.getvalue(),
            file_name=f"{filename_stem}_{ts}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key=f"btn_{widget_key}_xlsx",
            help="ì„œì‹ ìœ ì§€ê°€ í•„ìš”í•œ ê²½ìš° XLSXë¡œ ì €ì¥í•˜ì„¸ìš”.",
        )

# -------------------- Defaults --------------------
DEFAULT_TEMPLATE_COLUMNS = [
    "ì£¼ë¬¸ë²ˆí˜¸",
    "ë°›ëŠ”ë¶„ ì´ë¦„",
    "ë°›ëŠ”ë¶„ ì£¼ì†Œ",
    "ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸",
    "ìƒí’ˆëª…",
    "ìˆ˜ëŸ‰",
    "ë©”ëª¨",
]

# ë¼ì˜¤ ê¸°ë³¸ ë§¤í•‘ (ì—´ ë¬¸ì)
DEFAULT_MAPPING = {
    "ì£¼ë¬¸ë²ˆí˜¸": "A",
    "ë°›ëŠ”ë¶„ ì´ë¦„": "I",
    "ë°›ëŠ”ë¶„ ì£¼ì†Œ": "L",
    "ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸": "J",
    "ìƒí’ˆëª…": "D",
    "ìˆ˜ëŸ‰": "G",
    "ë©”ëª¨": "M",
}

# ì¿ íŒ¡ ê³ ì • ë§¤í•‘ (ì—´ ë¬¸ì) â€” ì£¼ë¬¸ë²ˆí˜¸ C
COUPANG_MAPPING = {
    "ì£¼ë¬¸ë²ˆí˜¸": "C",
    "ë°›ëŠ”ë¶„ ì´ë¦„": "AA",
    "ë°›ëŠ”ë¶„ ì£¼ì†Œ": "AD",
    "ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸": "AB",
    "ìƒí’ˆëª…": "P",
    "ìˆ˜ëŸ‰": "W",
    "ë©”ëª¨": "AE",
}

# ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ í‚¤ì›Œë“œ ë§¤í•‘ìš© í›„ë³´
SS_NAME_MAP = {
    "ì£¼ë¬¸ë²ˆí˜¸": ["ì£¼ë¬¸ë²ˆí˜¸"],
    "ë°›ëŠ”ë¶„ ì´ë¦„": ["ìˆ˜ì·¨ì¸ëª…"],
    "ë°›ëŠ”ë¶„ ì£¼ì†Œ": ["í†µí•©ë°°ì†¡ì§€"],
    "ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸": ["ìˆ˜ì·¨ì¸ì—°ë½ì²˜1", "ìˆ˜ì·¨ì¸ì—°ë½ì²˜", "ìˆ˜ì·¨ì¸íœ´ëŒ€í°", "ì—°ë½ì²˜1"],
    "ìƒí’ˆëª…_left": ["ìƒí’ˆëª…"],
    "ìƒí’ˆëª…_right": ["ì˜µì…˜ì •ë³´", "ì˜µì…˜ëª…", "ì˜µì…˜ë‚´ìš©"],
    "ìˆ˜ëŸ‰": ["ìˆ˜ëŸ‰", "êµ¬ë§¤ìˆ˜ëŸ‰"],
    "ë©”ëª¨": ["ë°°ì†¡ë©”ì„¸ì§€", "ë°°ì†¡ë©”ì‹œì§€", "ë°°ì†¡ìš”ì²­ì‚¬í•­"],
}

# â˜… ë– ë¦¬ëª° í‚¤ì›Œë“œ ë§¤í•‘ìš© í›„ë³´ (S & V ê·œì¹™)
TTARIMALL_NAME_MAP = {
    "ì£¼ë¬¸ë²ˆí˜¸": ["ì£¼ë¬¸ë²ˆí˜¸", "ì£¼ë¬¸ID", "ì£¼ë¬¸ì½”ë“œ", "ì£¼ë¬¸ë²ˆí˜¸1"],
    "ë°›ëŠ”ë¶„ ì´ë¦„": ["ìˆ˜ë ¹ìëª…", "ë°›ëŠ”ë¶„", "ìˆ˜ì·¨ì¸ëª…", "ìˆ˜ë ¹ì"],
    "ë°›ëŠ”ë¶„ ì£¼ì†Œ": ["ì£¼ì†Œ", "ìˆ˜ë ¹ìì£¼ì†Œ", "ë°°ì†¡ì§€ì£¼ì†Œ", "í†µí•©ë°°ì†¡ì§€"],
    "ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸": ["ìˆ˜ë ¹ìì—°ë½ì²˜", "ì—°ë½ì²˜", "íœ´ëŒ€í°", "ì „í™”ë²ˆí˜¸", "ì—°ë½ì²˜1"],
    "ìƒí’ˆëª…_S": ["ìƒí’ˆëª…(S)", "ìƒí’ˆëª…_S", "ìƒí’ˆëª…S", "íŒë§¤ìƒí’ˆëª…", "ìƒí’ˆëª…"],
    "ìƒí’ˆëª…_V": ["ì˜µì…˜ëª…:ì˜µì…˜ê°’", "ì˜µì…˜", "ì˜µì…˜ëª…", "ì˜µì…˜ì •ë³´", "ì˜µì…˜ë‚´ìš©", "ì˜µì…˜ê°’", "ìƒí’ˆì˜µì…˜"],
    "ìˆ˜ëŸ‰": ["ìˆ˜ëŸ‰", "êµ¬ë§¤ìˆ˜", "ì£¼ë¬¸ìˆ˜ëŸ‰"],
    "ë©”ëª¨": ["ë°°ì†¡ë©”ì‹œì§€", "ë°°ì†¡ë©”ì„¸ì§€", "ë°°ì†¡ìš”ì²­ì‚¬í•­", "ë©”ëª¨"],
}

# -------------------------- Sidebar --------------------------
st.sidebar.header("í…œí”Œë¦¿ ì˜µì…˜")
use_uploaded_template = st.sidebar.checkbox("í…œí”Œë¦¿(2.xlsx) ì§ì ‘ ì—…ë¡œë“œ", value=False)
max_letter_cols = st.sidebar.slider(
    "ë¼ì˜¤ë¼ìš© ìµœëŒ€ ì—´ ë²”ìœ„(Excel ë¬¸ì)",
    min_value=52,
    max_value=156,
    value=104,
    step=26,
    help="ë¼ì˜¤ë¼ ë§¤í•‘ ë“œë¡­ë‹¤ìš´ì˜ ì—´ ë¬¸ì ê°œìˆ˜",
)
st.sidebar.divider()
st.sidebar.subheader("ë¼ì˜¤ë¼ ë§¤í•‘ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°")
mapping_upload = st.sidebar.file_uploader("ë§¤í•‘ JSON ë¶ˆëŸ¬ì˜¤ê¸° (ë¼ì˜¤ë¼)", type=["json"], key="mapping_json")
prepare_download = st.sidebar.button("í˜„ì¬ ë¼ì˜¤ë¼ ë§¤í•‘ JSON ë‹¤ìš´ë¡œë“œ ì¤€ë¹„")

# â˜… CSV ì¶œë ¥ ì„¤ì •
st.sidebar.divider()
st.sidebar.header("CSV ì¶œë ¥ ì„¤ì •")
sep_label = st.sidebar.selectbox("êµ¬ë¶„ì", list(CSV_SEPARATORS.keys()), index=0, help="ì—‘ì…€ì—ì„œ ì‰¼í‘œë¡œ ì¸ì‹í•˜ê²Œ í•˜ë ¤ë©´ 'ì‰¼í‘œ(,)'ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
enc_label = st.sidebar.selectbox("ì¸ì½”ë”©", list(CSV_ENCODINGS.keys()), index=0, help="ì—‘ì…€ í˜¸í™˜ì—ëŠ” ë³´í†µ 'UTF-8-SIG (ê¶Œì¥)'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
st.session_state["csv_sep_label"] = sep_label
st.session_state["csv_enc_label"] = enc_label
st.session_state["csv_sep"] = CSV_SEPARATORS[sep_label]
st.session_state["csv_encoding"] = CSV_ENCODINGS[enc_label]

# -------------------------- í…œí”Œë¦¿ ì„¤ì • (ê³µìš©) --------------------------
st.subheader("í…œí”Œë¦¿ ì„¤ì • (2.xlsx)")
tpl_df = None
if use_uploaded_template:
    tpl_file = st.file_uploader("2ì™€ ê°™ì€ í…œí”Œë¦¿ íŒŒì¼ ì—…ë¡œë“œ (ì˜ˆ: 2.xlsx)", type=["xlsx"], key="tpl")
    if tpl_file:
        try:
            tpl_df = read_first_sheet_template(tpl_file)
            st.success(f"í…œí”Œë¦¿ ì—…ë¡œë“œ ì™„ë£Œ. ì»¬ëŸ¼ ìˆ˜: {len(tpl_df.columns)}")
        except Exception as e:
            st.warning(f"í…œí”Œë¦¿ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            tpl_df = None
else:
    tpl_df = pd.DataFrame(columns=DEFAULT_TEMPLATE_COLUMNS)
    st.info("ì—…ë¡œë“œëœ í…œí”Œë¦¿ì´ ì—†ìœ¼ë¯€ë¡œ ê¸°ë³¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (ì£¼ë¬¸ë²ˆí˜¸, ë°›ëŠ”ë¶„ ì´ë¦„, ë°›ëŠ”ë¶„ ì£¼ì†Œ, ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸, ìƒí’ˆëª…, ìˆ˜ëŸ‰, ë©”ëª¨)")

template_columns = list(tpl_df.columns) if tpl_df is not None else []

# ======================================================================
# 1) ë¼ì˜¤ë¼ íŒŒì¼ ë³€í™˜ (ì—´ ë¬¸ì ë§¤í•‘)
# ======================================================================
st.markdown("## ë¼ì˜¤ë¼ íŒŒì¼ ë³€í™˜")

current_mapping = ensure_mapping_initialized(template_columns, DEFAULT_MAPPING)
letters = excel_letters(max_letter_cols)

if mapping_upload is not None:
    try:
        loaded = json.load(mapping_upload)
        if not isinstance(loaded, dict):
            raise ValueError("JSON ë£¨íŠ¸ê°€ ê°ì²´(dict)ê°€ ì•„ë‹™ë‹ˆë‹¤.")
        new_map = {}
        for k, v in loaded.items():
            if k in template_columns and isinstance(v, str) and re.fullmatch(r"[A-Za-z]+", v):
                new_map[k] = v.upper()
        for k in template_columns:
            if k not in new_map:
                new_map[k] = current_mapping.get(k, DEFAULT_MAPPING.get(k, ""))
        st.session_state["mapping"] = new_map
        current_mapping = new_map
        st.success("ë¼ì˜¤ë¼ ë§¤í•‘ JSONì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.warning(f"ë¼ì˜¤ë¼ ë§¤í•‘ JSON ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")

edited_mapping = {}
with st.form("mapping_form_laora"):
    for col in template_columns:
        default_val = current_mapping.get(col, "")
        if default_val not in letters:
            default_val = ""
        options = [""] + letters
        sel = st.selectbox(
            f"{col} âŸ¶ 1.xlsx(ë¼ì˜¤ë¼) ì—´ ë¬¸ì ì„ íƒ",
            options=options,
            index=(options.index(default_val) if default_val in options else 0),
            key=f"map_laora_{col}",
        )
        edited_mapping[col] = sel
    if st.form_submit_button("ë¼ì˜¤ë¼ ë§¤í•‘ ì €ì¥"):
        st.session_state["mapping"] = {k: v for k, v in edited_mapping.items() if v}
        current_mapping = st.session_state["mapping"]
        st.success("ë¼ì˜¤ë¼ ë§¤í•‘ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

if prepare_download:
    mapping_bytes = json.dumps(current_mapping, ensure_ascii=False, indent=2).encode("utf-8")
    st.download_button(
        label="í˜„ì¬ ë¼ì˜¤ë¼ ë§¤í•‘ JSON ë‹¤ìš´ë¡œë“œ",
        data=mapping_bytes,
        file_name="mapping_laora.json",
        mime="application/json",
    )

st.subheader("ë¼ì˜¤ë¼ ì†ŒìŠ¤ íŒŒì¼ ì—…ë¡œë“œ")
src_file_laora = st.file_uploader("ë¼ì˜¤ë¼ í˜•ì‹ì˜ íŒŒì¼ ì—…ë¡œë“œ (ì˜ˆ: 1.xlsx)", type=["xlsx"], key="src_laora")
run_laora = st.button("ë¼ì˜¤ë¼ ë³€í™˜ ì‹¤í–‰")
if run_laora:
    if not src_file_laora:
        st.error("ë¼ì˜¤ë¼ ì†ŒìŠ¤ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    elif tpl_df is None or len(template_columns) == 0:
        st.error("ìœ íš¨í•œ í…œí”Œë¦¿ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        try:
            df_src = read_first_sheet_source_as_text(src_file_laora)
        except Exception as e:
            st.exception(RuntimeError(f"ë¼ì˜¤ë¼ ì†ŒìŠ¤ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜: {e}"))
        else:
            result = pd.DataFrame(index=range(len(df_src)), columns=template_columns)
            mapping = st.session_state.get("mapping", {})
            if not isinstance(mapping, dict) or not mapping:
                st.error("ë¼ì˜¤ë¼ ë§¤í•‘ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì €ì¥í•´ ì£¼ì„¸ìš”.")
            else:
                src_cols_by_index = list(df_src.columns)
                resolved_map = {}
                try:
                    for tpl_header, xl_letters in mapping.items():
                        if not xl_letters:
                            continue
                        idx = excel_col_to_index(xl_letters)
                        if idx >= len(src_cols_by_index):
                            raise IndexError(
                                f"ì†ŒìŠ¤ íŒŒì¼ì— {xl_letters} ì—´(0-based index {idx})ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
                                f"ì†ŒìŠ¤ ì»¬ëŸ¼ ìˆ˜: {len(src_cols_by_index)}"
                            )
                        resolved_map[tpl_header] = src_cols_by_index[idx]
                except Exception as e:
                    st.exception(RuntimeError(f"ë¼ì˜¤ë¼ ë§¤í•‘ ì¸ë±ìŠ¤ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}"))
                else:
                    for tpl_header, src_colname in resolved_map.items():
                        try:
                            if tpl_header == "ìˆ˜ëŸ‰":
                                result[tpl_header] = pd.to_numeric(df_src[src_colname], errors="coerce")
                            elif tpl_header == "ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸":
                                series = df_src[src_colname].astype(str)
                                result[tpl_header] = series.where(series.str.lower() != "nan", "")
                            else:
                                result[tpl_header] = df_src[src_colname]
                        except KeyError:
                            st.warning(f"ì†ŒìŠ¤ ì»¬ëŸ¼ '{src_colname}'(ë§¤í•‘: {tpl_header})ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•´ë‹¹ í•„ë“œëŠ” ë¹„ì›Œì§‘ë‹ˆë‹¤.")

                    # í…œí”Œë¦¿ ìˆ«ìí˜• ì •ë ¬(ì „í™”ë²ˆí˜¸ ì œì™¸)
                    for col in template_columns:
                        if col in tpl_df.columns and tpl_df[col].notna().any():
                            if pd.api.types.is_numeric_dtype(tpl_df[col]) and col != "ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸":
                                result[col] = pd.to_numeric(result[col], errors="coerce")

                    st.success(f"ë¼ì˜¤ë¼ ë³€í™˜ ì™„ë£Œ: ì´ {len(result)}í–‰")
                    st.dataframe(result.head(50))

                    out_df = result[template_columns + [c for c in result.columns if c not in template_columns]]
                    download_df(out_df, "ë¼ì˜¤ë¼ ë³€í™˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", "ë¼ì˜¤ 3plë°œì£¼ìš©", "laora_conv")

st.markdown("---")

# ======================================================================
# 2) ì¿ íŒ¡ íŒŒì¼ ë³€í™˜ (ê³ ì • ë§¤í•‘)
# ======================================================================
st.markdown("## ì¿ íŒ¡ íŒŒì¼ ë³€í™˜")

with st.expander("ì¿ íŒ¡ â†’ í…œí”Œë¦¿ ë§¤í•‘ ë³´ê¸°", expanded=False):
    st.markdown(
        """
        **ì¿ íŒ¡ ì†ŒìŠ¤ì—´ â†’ í…œí”Œë¦¿ ì»¬ëŸ¼**  
        - `C` â†’ **ì£¼ë¬¸ë²ˆí˜¸**  
        - `AA` â†’ **ë°›ëŠ”ë¶„ ì´ë¦„**  
        - `AD` â†’ **ë°›ëŠ”ë¶„ ì£¼ì†Œ**  
        - `AB` â†’ **ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸**  
        - `P` â†’ **ìƒí’ˆëª…** (ìµœì´ˆë“±ë¡ìƒí’ˆëª…/ì˜µì…˜ëª…)  
        - `W` â†’ **ìˆ˜ëŸ‰** (êµ¬ë§¤ìˆ˜)  
        - `AE` â†’ **ë©”ëª¨** (ë°°ì†¡ë©”ì‹œì§€)
        """
    )

st.subheader("ì¿ íŒ¡ ì†ŒìŠ¤ íŒŒì¼ ì—…ë¡œë“œ")
src_file_coupang = st.file_uploader("ì¿ íŒ¡ í˜•ì‹ì˜ íŒŒì¼ ì—…ë¡œë“œ (ì˜ˆ: ì¿ íŒ¡.xlsx)", type=["xlsx"], key="src_coupang")
run_coupang = st.button("ì¿ íŒ¡ ë³€í™˜ ì‹¤í–‰")
if run_coupang:
    if not src_file_coupang:
        st.error("ì¿ íŒ¡ ì†ŒìŠ¤ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    elif tpl_df is None or len(template_columns) == 0:
        st.error("ìœ íš¨í•œ í…œí”Œë¦¿ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        try:
            df_src_cp = read_first_sheet_source_as_text(src_file_coupang)
        except Exception as e:
            st.exception(RuntimeError(f"ì¿ íŒ¡ ì†ŒìŠ¤ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜: {e}"))
        else:
            result_cp = pd.DataFrame(index=range(len(df_src_cp)), columns=template_columns)
            mapping_cp = COUPANG_MAPPING.copy()

            src_cols_by_index_cp = list(df_src_cp.columns)
            resolved_map_cp = {}
            try:
                for tpl_header, xl_letters in mapping_cp.items():
                    idx = excel_col_to_index(xl_letters)
                    if idx >= len(src_cols_by_index_cp):
                        raise IndexError(
                            f"ì¿ íŒ¡ ì†ŒìŠ¤ì— {xl_letters} ì—´(0-based index {idx})ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
                            f"ì†ŒìŠ¤ ì»¬ëŸ¼ ìˆ˜: {len(src_cols_by_index_cp)}"
                        )
                    resolved_map_cp[tpl_header] = src_cols_by_index_cp[idx]
            except Exception as e:
                st.exception(RuntimeError(f"ì¿ íŒ¡ ë§¤í•‘ ì¸ë±ìŠ¤ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}"))
            else:
                for tpl_header, src_colname in resolved_map_cp.items():
                    try:
                        if tpl_header == "ìˆ˜ëŸ‰":
                            result_cp[tpl_header] = pd.to_numeric(df_src_cp[src_colname], errors="coerce")
                        elif tpl_header == "ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸":
                            series = df_src_cp[src_colname].astype(str)
                            result_cp[tpl_header] = series.where(series.str.lower() != "nan", "")
                        else:
                            result_cp[tpl_header] = df_src_cp[src_colname]
                    except KeyError:
                        st.warning(f"[ì¿ íŒ¡] ì†ŒìŠ¤ ì»¬ëŸ¼ '{src_colname}'(ë§¤í•‘: {tpl_header})ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•´ë‹¹ í•„ë“œëŠ” ë¹„ì›Œì§‘ë‹ˆë‹¤.")

                # í…œí”Œë¦¿ ìˆ«ìí˜• ì •ë ¬(ì „í™”ë²ˆí˜¸ ì œì™¸)
                for col in template_columns:
                    if col in tpl_df.columns and tpl_df[col].notna().any():
                        if pd.api.types.is_numeric_dtype(tpl_df[col]) and col != "ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸":
                            result_cp[col] = pd.to_numeric(result_cp[col], errors="coerce")

                st.success(f"ì¿ íŒ¡ ë³€í™˜ ì™„ë£Œ: ì´ {len(result_cp)}í–‰")
                st.dataframe(result_cp.head(50))

                out_df_cp = result_cp[template_columns + [c for c in result_cp.columns if c not in template_columns]]
                download_df(out_df_cp, "ì¿ íŒ¡ ë³€í™˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", "ì¿ íŒ¡ 3plë°œì£¼ìš©", "coupang_conv")

st.markdown("---")

# ======================================================================
# 3) ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ íŒŒì¼ ë³€í™˜ (í‚¤ì›Œë“œ ë§¤í•‘)
# ======================================================================
st.markdown("## ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ íŒŒì¼ ë³€í™˜ (í‚¤ì›Œë“œ ë§¤í•‘)")

with st.expander("ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´(í‚¤ì›Œë“œ) â†’ í…œí”Œë¦¿ ë§¤í•‘ ë³´ê¸°", expanded=False):
    st.markdown(
        """
        **ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì»¬ëŸ¼ëª…(í—¤ë”) â†’ í…œí”Œë¦¿ ì»¬ëŸ¼**  
        - `ì£¼ë¬¸ë²ˆí˜¸` â†’ **ì£¼ë¬¸ë²ˆí˜¸**  
        - `ìˆ˜ì·¨ì¸ëª…` â†’ **ë°›ëŠ”ë¶„ ì´ë¦„**  
        - `í†µí•©ë°°ì†¡ì§€` â†’ **ë°›ëŠ”ë¶„ ì£¼ì†Œ**  
        - `ìˆ˜ì·¨ì¸ì—°ë½ì²˜1` â†’ **ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸**  
        - `=ìƒí’ˆëª…&ì˜µì…˜ì •ë³´` â†’ **ìƒí’ˆëª…** (ë‘ ê°’ì„ ê·¸ëŒ€ë¡œ ì—°ê²°)  
        - `ìˆ˜ëŸ‰` â†’ **ìˆ˜ëŸ‰**  
        - `ë°°ì†¡ë©”ì„¸ì§€` â†’ **ë©”ëª¨**  (â€» ì¼ë¶€ íŒŒì¼ì€ `ë°°ì†¡ë©”ì‹œì§€` í‘œê¸°)
        """
    )

st.subheader("ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì†ŒìŠ¤ íŒŒì¼ ì—…ë¡œë“œ (í‚¤ì›Œë“œ ë§¤í•‘)")
src_file_ss_fixed = st.file_uploader(
    "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ í˜•ì‹ì˜ íŒŒì¼ ì—…ë¡œë“œ (ì˜ˆ: ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´.xlsx)",
    type=["xlsx"],
    key="src_smartstore_fixed",
)

run_ss_fixed = st.button("ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ë³€í™˜ ì‹¤í–‰ (í‚¤ì›Œë“œ ë§¤í•‘)")
if run_ss_fixed:
    if not src_file_ss_fixed:
        st.error("ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì†ŒìŠ¤ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    elif tpl_df is None or len(template_columns) == 0:
        st.error("ìœ íš¨í•œ í…œí”Œë¦¿ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        try:
            df_ss = read_first_sheet_source_as_text(src_file_ss_fixed)
        except Exception as e:
            st.exception(RuntimeError(f"ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì†ŒìŠ¤ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜: {e}"))
        else:
            def find_col(preferred_names, df):
                norm_cols = {norm_header(c): c for c in df.columns}
                cand_norm = [norm_header(x) for x in preferred_names]
                for n in cand_norm:
                    if n in norm_cols:
                        return norm_cols[n]
                for want in cand_norm:
                    hits = [orig for k, orig in norm_cols.items() if want in k]
                    if hits:
                        return sorted(hits, key=len)[0]
                raise KeyError(f"í•´ë‹¹ í‚¤ì›Œë“œì— ë§ëŠ” ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {preferred_names}")

            try:
                col_order = find_col(SS_NAME_MAP["ì£¼ë¬¸ë²ˆí˜¸"], df_ss)
                col_name = find_col(SS_NAME_MAP["ë°›ëŠ”ë¶„ ì´ë¦„"], df_ss)
                col_addr = find_col(SS_NAME_MAP["ë°›ëŠ”ë¶„ ì£¼ì†Œ"], df_ss)
                col_phone = find_col(SS_NAME_MAP["ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸"], df_ss)
                col_prod_l = find_col(SS_NAME_MAP["ìƒí’ˆëª…_left"], df_ss)
                col_prod_r = find_col(SS_NAME_MAP["ìƒí’ˆëª…_right"], df_ss)
                col_qty = find_col(SS_NAME_MAP["ìˆ˜ëŸ‰"], df_ss)
                col_memo = find_col(SS_NAME_MAP["ë©”ëª¨"], df_ss)
            except Exception as e:
                st.exception(RuntimeError(f"ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ í‚¤ì›Œë“œ ë§¤í•‘ í•´ì„ ì¤‘ ì˜¤ë¥˜: {e}"))
            else:
                result_ss = pd.DataFrame(index=range(len(df_ss)), columns=template_columns)

                result_ss["ì£¼ë¬¸ë²ˆí˜¸"] = df_ss[col_order]
                result_ss["ë°›ëŠ”ë¶„ ì´ë¦„"] = df_ss[col_name]
                result_ss["ë°›ëŠ”ë¶„ ì£¼ì†Œ"] = df_ss[col_addr]

                series_phone = df_ss[col_phone].astype(str)
                result_ss["ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸"] = series_phone.where(series_phone.str.lower() != "nan", "")

                left_raw = df_ss[col_prod_l].astype(str)
                right_raw = df_ss[col_prod_r].astype(str)
                left = left_raw.where(left_raw.str.lower() != "nan", "")
                right = right_raw.where(right_raw.str.lower() != "nan", "")
                result_ss["ìƒí’ˆëª…"] = (left.fillna("") + right.fillna(""))

                result_ss["ìˆ˜ëŸ‰"] = pd.to_numeric(df_ss[col_qty], errors="coerce")
                result_ss["ë©”ëª¨"] = df_ss[col_memo]

                for col in template_columns:
                    if col in tpl_df.columns and tpl_df[col].notna().any():
                        if pd.api.types.is_numeric_dtype(tpl_df[col]) and col != "ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸":
                            result_ss[col] = pd.to_numeric(result_ss[col], errors="coerce")

                st.success(f"ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´(í‚¤ì›Œë“œ) ë³€í™˜ ì™„ë£Œ: ì´ {len(result_ss)}í–‰")
                st.dataframe(result_ss.head(50))

                out_df_ss = result_ss[template_columns + [c for c in result_ss.columns if c not in template_columns]]
                download_df(
                    out_df_ss,
                    "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ë³€í™˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                    "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ 3plë°œì£¼ìš©",
                    "ss_conv",
                    sheet_name="ë°œì†¡ì²˜ë¦¬",        # â˜… ì‹œíŠ¸ëª… ê³ ì •
                    csv_sep_override=",",         # â˜… CSV ì‰¼í‘œ ê³ ì •
                    csv_encoding_override=None,   # (í•„ìš”ì‹œ "utf-8-sig"ë¡œ ê³ ì • ê°€ëŠ¥)
                )

st.markdown("---")

# ======================================================================
# 4) ë– ë¦¬ëª° íŒŒì¼ ë³€í™˜ (í‚¤ì›Œë“œ ë§¤í•‘: S&V ê·œì¹™)
# ======================================================================
st.markdown("## ë– ë¦¬ëª° íŒŒì¼ ë³€í™˜ (í‚¤ì›Œë“œ ë§¤í•‘)")

with st.expander("ë– ë¦¬ëª°(í‚¤ì›Œë“œ) â†’ í…œí”Œë¦¿ ë§¤í•‘ ë³´ê¸°", expanded=False):
    st.markdown(
        """
        **ë– ë¦¬ëª° ì»¬ëŸ¼ëª…(í—¤ë”) â†’ í…œí”Œë¦¿ ì»¬ëŸ¼**  
        - `ì£¼ë¬¸ë²ˆí˜¸/ì£¼ë¬¸ID/...` â†’ **ì£¼ë¬¸ë²ˆí˜¸**  
        - `ìˆ˜ë ¹ìëª…/ë°›ëŠ”ë¶„/...` â†’ **ë°›ëŠ”ë¶„ ì´ë¦„**  
        - `ì£¼ì†Œ/ë°°ì†¡ì§€ì£¼ì†Œ/...` â†’ **ë°›ëŠ”ë¶„ ì£¼ì†Œ**  
        - `ìˆ˜ë ¹ìì—°ë½ì²˜/ì—°ë½ì²˜/íœ´ëŒ€í°/...` â†’ **ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸**  
        - `ìƒí’ˆëª…(S)` & `ì˜µì…˜ëª…:ì˜µì…˜ê°’`(ë˜ëŠ” ì˜µì…˜ ê´€ë ¨ ì»¬ëŸ¼) â†’ **ìƒí’ˆëª…**  
          (Sì™€ Vê°€ ê°™ìœ¼ë©´ Vë§Œ, ë‹¤ë¥´ë©´ S+V ê·¸ëŒ€ë¡œ ì—°ê²°)  
        - `ìˆ˜ëŸ‰/êµ¬ë§¤ìˆ˜/...` â†’ **ìˆ˜ëŸ‰**  
        - `ë°°ì†¡ë©”ì‹œì§€/ë©”ëª¨/...` â†’ **ë©”ëª¨**
        """
    )

st.subheader("ë– ë¦¬ëª° ì†ŒìŠ¤ íŒŒì¼ ì—…ë¡œë“œ (í‚¤ì›Œë“œ ë§¤í•‘)")
src_file_ttarimall = st.file_uploader("ë– ë¦¬ëª° í˜•ì‹ì˜ íŒŒì¼ ì—…ë¡œë“œ (ì˜ˆ: ë– ë¦¬ëª°.xlsx)", type=["xlsx"], key="src_ttarimall")

# ê³µìš© find_col
def find_col(preferred_names, df):
    norm_cols = {norm_header(c): c for c in df.columns}
    cand_norm = [norm_header(x) for x in preferred_names]
    for n in cand_norm:
        if n in norm_cols:
            return norm_cols[n]
    for want in cand_norm:
        hits = [orig for k, orig in norm_cols.items() if want in k]
        if hits:
            return sorted(hits, key=len)[0]
    raise KeyError(f"í•´ë‹¹ í‚¤ì›Œë“œì— ë§ëŠ” ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {preferred_names}")

def convert_ttarimall_keywords(df_tm: pd.DataFrame) -> pd.DataFrame:
    col_order = find_col(TTARIMALL_NAME_MAP["ì£¼ë¬¸ë²ˆí˜¸"], df_tm)
    col_name  = find_col(TTARIMALL_NAME_MAP["ë°›ëŠ”ë¶„ ì´ë¦„"], df_tm)
    col_addr  = find_col(TTARIMALL_NAME_MAP["ë°›ëŠ”ë¶„ ì£¼ì†Œ"], df_tm)
    col_phone = find_col(TTARIMALL_NAME_MAP["ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸"], df_tm)
    col_s     = find_col(TTARIMALL_NAME_MAP["ìƒí’ˆëª…_S"], df_tm)
    col_v     = find_col(TTARIMALL_NAME_MAP["ìƒí’ˆëª…_V"], df_tm)
    col_qty   = find_col(TTARIMALL_NAME_MAP["ìˆ˜ëŸ‰"], df_tm)
    col_memo  = find_col(TTARIMALL_NAME_MAP["ë©”ëª¨"], df_tm)

    result_tm = pd.DataFrame(index=range(len(df_tm)), columns=template_columns)

    result_tm["ì£¼ë¬¸ë²ˆí˜¸"] = df_tm[col_order]
    result_tm["ë°›ëŠ”ë¶„ ì´ë¦„"] = df_tm[col_name]
    result_tm["ë°›ëŠ”ë¶„ ì£¼ì†Œ"] = df_tm[col_addr]

    series_phone = df_tm[col_phone].astype(str)
    result_tm["ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸"] = series_phone.where(series_phone.str.lower() != "nan", "")

    s_series_raw = df_tm[col_s].astype(str)
    v_series_raw = df_tm[col_v].astype(str)
    s_series = s_series_raw.where(s_series_raw.str.lower() != "nan", "")
    v_series = v_series_raw.where(v_series_raw.str.lower() != "nan", "")
    same_mask = (s_series == v_series)
    prod_series = v_series.copy()
    prod_series.loc[~same_mask] = s_series[~same_mask] + v_series[~same_mask]
    result_tm["ìƒí’ˆëª…"] = prod_series

    result_tm["ìˆ˜ëŸ‰"] = pd.to_numeric(df_tm[col_qty], errors="coerce")
    result_tm["ë©”ëª¨"] = df_tm[col_memo]

    return result_tm

run_ttarimall = st.button("ë– ë¦¬ëª° ë³€í™˜ ì‹¤í–‰ (í‚¤ì›Œë“œ ë§¤í•‘)")
if run_ttarimall:
    if not src_file_ttarimall:
        st.error("ë– ë¦¬ëª° ì†ŒìŠ¤ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    elif tpl_df is None or len(template_columns) == 0:
        st.error("ìœ íš¨í•œ í…œí”Œë¦¿ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        try:
            df_tm = read_first_sheet_source_as_text(src_file_ttarimall)
        except Exception as e:
            st.exception(RuntimeError(f"ë– ë¦¬ëª° ì†ŒìŠ¤ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜: {e}"))
        else:
            try:
                result_tm = convert_ttarimall_keywords(df_tm)

                # í…œí”Œë¦¿ ìˆ«ìí˜• ì •ë ¬(ì „í™”ë²ˆí˜¸ ì œì™¸)
                for col in template_columns:
                    if col in tpl_df.columns and tpl_df[col].notna().any():
                        if pd.api.types.is_numeric_dtype(tpl_df[col]) and col != "ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸":
                            result_tm[col] = pd.to_numeric(result_tm[col], errors="coerce")

                st.success(f"ë– ë¦¬ëª°(í‚¤ì›Œë“œ) ë³€í™˜ ì™„ë£Œ: ì´ {len(result_tm)}í–‰")
                st.dataframe(result_tm.head(50))

                out_df_tm = result_tm[template_columns + [c for c in result_tm.columns if c not in template_columns]]
                download_df(out_df_tm, "ë– ë¦¬ëª° ë³€í™˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", "ë– ë¦¬ëª° 3plë°œì£¼ìš©", "ttarimall_conv")
            except Exception as e:
                st.exception(RuntimeError(f"ë– ë¦¬ëª° í‚¤ì›Œë“œ ë§¤í•‘ í•´ì„ ì¤‘ ì˜¤ë¥˜: {e}"))

st.markdown("---")

# ======================================================================
# 5) ë°°ì¹˜ ì²˜ë¦¬: ì—¬ëŸ¬ íŒŒì¼ ìë™ ë¶„ë¥˜ â†’ ì¼ê´„ ë³€í™˜ â†’ ZIP ë‹¤ìš´ë¡œë“œ
# ======================================================================
st.markdown("## ğŸ—‚ï¸ ë°°ì¹˜ ì²˜ë¦¬ (ì—¬ëŸ¬ íŒŒì¼ í•œë²ˆì—)")

batch_files = st.file_uploader("ì—¬ëŸ¬ ì—‘ì…€ íŒŒì¼ì„ í•œë²ˆì— ì—…ë¡œë“œí•˜ì„¸ìš”", type=["xlsx"], accept_multiple_files=True, key="batch_files")
run_batch = st.button("ë°°ì¹˜ ë³€í™˜ ì‹¤í–‰")

def detect_platform_by_headers(df: pd.DataFrame) -> str:
    headers = [norm_header(c) for c in df.columns]

    def has_any(keys):
        keys_norm = [norm_header(k) for k in keys]
        return any(k in headers for k in keys_norm)

    # ë– ë¦¬ëª° ê°ì§€ í‚¤ì›Œë“œ
    if has_any(["ìˆ˜ë ¹ìëª…", "ìˆ˜ë ¹ìì—°ë½ì²˜", "ì˜µì…˜ëª…:ì˜µì…˜ê°’"]):
        return "TTARIMALL"
    if has_any(["ìˆ˜ì·¨ì¸ëª…", "ìˆ˜ì·¨ì¸ì—°ë½ì²˜1", "í†µí•©ë°°ì†¡ì§€"]):
        return "SMARTSTORE"
    if has_any(["ìµœì´ˆë“±ë¡ìƒí’ˆëª…"]) or (has_any(["êµ¬ë§¤ìˆ˜"]) and has_any(["ì˜µì…˜ëª…"])) or has_any(["ë°°ì†¡ë©”ì‹œì§€"]):
        return "COUPANG"
    return "LAORA"

def convert_laora(df_src: pd.DataFrame) -> pd.DataFrame:
    mapping = st.session_state.get("mapping", {})
    if not isinstance(mapping, dict) or not mapping:
        raise RuntimeError("ë¼ì˜¤ë¼ ë§¤í•‘ì´ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ë¼ì˜¤ë¼ ë§¤í•‘ì„ ë¨¼ì € ì €ì¥í•´ ì£¼ì„¸ìš”.")
    result = pd.DataFrame(index=range(len(df_src)), columns=template_columns)
    src_cols_by_index = list(df_src.columns)
    resolved_map = {}
    for tpl_header, xl_letters in st.session_state["mapping"].items():
        if not xl_letters:
            continue
        idx = excel_col_to_index(xl_letters)
        if idx >= len(src_cols_by_index):
            raise IndexError(
                f"ì†ŒìŠ¤ íŒŒì¼ì— {xl_letters} ì—´(0-based index {idx})ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
                f"ì†ŒìŠ¤ ì»¬ëŸ¼ ìˆ˜: {len(src_cols_by_index)}"
            )
        resolved_map[tpl_header] = src_cols_by_index[idx]
    for tpl_header, src_colname in resolved_map.items():
        if tpl_header == "ìˆ˜ëŸ‰":
            result[tpl_header] = pd.to_numeric(df_src[src_colname], errors="coerce")
        elif tpl_header == "ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸":
            series = df_src[src_colname].astype(str)
            result[tpl_header] = series.where(series.str.lower() != "nan", "")
        else:
            result[tpl_header] = df_src[src_colname]
    return result

def convert_coupang(df_src: pd.DataFrame) -> pd.DataFrame:
    result = pd.DataFrame(index=range(len(df_src)), columns=template_columns)
    src_cols_by_index = list(df_src.columns)
    resolved_map = {}
    for tpl_header, xl_letters in COUPANG_MAPPING.items():
        idx = excel_col_to_index(xl_letters)
        if idx >= len(src_cols_by_index):
            raise IndexError(
                f"ì¿ íŒ¡ ì†ŒìŠ¤ì— {xl_letters} ì—´(0-based index {idx})ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
                f"ì†ŒìŠ¤ ì»¬ëŸ¼ ìˆ˜: {len(src_cols_by_index)}"
            )
        resolved_map[tpl_header] = src_cols_by_index[idx]
    for tpl_header, src_colname in resolved_map.items():
        if tpl_header == "ìˆ˜ëŸ‰":
            result[tpl_header] = pd.to_numeric(df_src[src_colname], errors="coerce")
        elif tpl_header == "ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸":
            series = df_src[src_colname].astype(str)
            result[tpl_header] = series.where(series.str.lower() != "nan", "")
        else:
            result[tpl_header] = df_src[src_colname]
    return result

def convert_smartstore_keywords(df_ss: pd.DataFrame) -> pd.DataFrame:
    col_order = find_col(SS_NAME_MAP["ì£¼ë¬¸ë²ˆí˜¸"], df_ss)
    col_name = find_col(SS_NAME_MAP["ë°›ëŠ”ë¶„ ì´ë¦„"], df_ss)
    col_addr = find_col(SS_NAME_MAP["ë°›ëŠ”ë¶„ ì£¼ì†Œ"], df_ss)
    col_phone = find_col(SS_NAME_MAP["ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸"], df_ss)
    col_prod_l = find_col(SS_NAME_MAP["ìƒí’ˆëª…_left"], df_ss)
    col_prod_r = find_col(SS_NAME_MAP["ìƒí’ˆëª…_right"], df_ss)
    col_qty = find_col(SS_NAME_MAP["ìˆ˜ëŸ‰"], df_ss)
    col_memo = find_col(SS_NAME_MAP["ë©”ëª¨"], df_ss)

    result = pd.DataFrame(index=range(len(df_ss)), columns=template_columns)
    result["ì£¼ë¬¸ë²ˆí˜¸"] = df_ss[col_order]
    result["ë°›ëŠ”ë¶„ ì´ë¦„"] = df_ss[col_name]
    result["ë°›ëŠ”ë¶„ ì£¼ì†Œ"] = df_ss[col_addr]
    phone = df_ss[col_phone].astype(str)
    result["ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸"] = phone.where(phone.str.lower() != "nan", "")
    lraw = df_ss[col_prod_l].astype(str)
    rraw = df_ss[col_prod_r].astype(str)
    l = lraw.where(lraw.str.lower() != "nan", "")
    r = rraw.where(rraw.str.lower() != "nan", "")
    result["ìƒí’ˆëª…"] = l.fillna("") + r.fillna("")
    result["ìˆ˜ëŸ‰"] = pd.to_numeric(df_ss[col_qty], errors="coerce")
    result["ë©”ëª¨"] = df_ss[col_memo]
    return result

def convert_ttarimall_keywords_for_batch(df_tm: pd.DataFrame) -> pd.DataFrame:
    return convert_ttarimall_keywords(df_tm)

def post_numeric_alignment(result_df: pd.DataFrame):
    # í…œí”Œë¦¿ ìˆ«ìí˜• ì •ë ¬(ì „í™”ë²ˆí˜¸ ì œì™¸)
    for col in template_columns:
        if col in result_df.columns and col in tpl_df.columns and tpl_df[col].notna().any():
            if pd.api.types.is_numeric_dtype(tpl_df[col]) and col != "ë°›ëŠ”ë¶„ ì „í™”ë²ˆí˜¸":
                result_df[col] = pd.to_numeric(result_df[col], errors="coerce")

if run_batch:
    if not batch_files:
        st.error("ì—‘ì…€ íŒŒì¼ì„ í•˜ë‚˜ ì´ìƒ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    elif tpl_df is None or len(template_columns) == 0:
        st.error("ìœ íš¨í•œ í…œí”Œë¦¿ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        zip_buffer = io.BytesIO()
        logs = []
        with zipfile.ZipFile(zip_buffer, "w", compression=zipfile.ZIP_DEFLATED) as zf:
            for f in batch_files:
                fname = getattr(f, "name", "uploaded.xlsx")
                try:
                    df = read_first_sheet_source_as_text(f)
                except Exception as e:
                    logs.append(f"[FAIL] {fname}: íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ - {e}")
                    continue

                platform = detect_platform_by_headers(df)
                try:
                    if platform == "TTARIMALL":
                        out_df = convert_ttarimall_keywords_for_batch(df)
                    elif platform == "SMARTSTORE":
                        out_df = convert_smartstore_keywords(df)
                    elif platform == "COUPANG":
                        out_df = convert_coupang(df)
                    else:  # LAORA
                        out_df = convert_laora(df)
                    post_numeric_alignment(out_df)

                    xbuf = io.BytesIO()
                    with pd.ExcelWriter(xbuf, engine="openpyxl") as writer:
                        out_df_sorted = out_df[template_columns + [c for c in out_df.columns if c not in template_columns]]
                        out_df_sorted.to_excel(writer, index=False)
                    base = fname.rsplit(".", 1)[0]
                    out_name = f"{base}__{platform.lower()}_converted.xlsx"
                    zf.writestr(out_name, xbuf.getvalue())

                    logs.append(f"[OK]   {fname}: {platform} â†’ rows={len(out_df)} â†’ {out_name}")
                except Exception as e:
                    logs.append(f"[FAIL] {fname}: {platform} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ - {e}")

            log_text = "Batch Convert Log - " + datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n" + "\n".join(logs)
            zf.writestr("batch_convert_log.txt", log_text)

        st.success("ë°°ì¹˜ ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.text_area("ë³€í™˜ ë¡œê·¸", value="\n".join(logs), height=200)
        st.download_button(
            label="ë°°ì¹˜ ë³€í™˜ ê²°ê³¼ ZIP ë‹¤ìš´ë¡œë“œ",
            data=zip_buffer.getvalue(),
            file_name=f"batch_converted_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
            mime="application/zip",
        )

st.caption("ë¼ì˜¤ë¼ / ì¿ íŒ¡ / ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´(í‚¤ì›Œë“œ) / ë– ë¦¬ëª°(í‚¤ì›Œë“œ S&V) ì™¸ ì–‘ì‹ë„ ì¶”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ê·œì¹™ë§Œ ì•Œë ¤ì£¼ì‹œë©´ ë°”ë¡œ ë„£ì–´ë“œë¦´ê²Œìš”.")

# ======================================================================
# 6) ì†¡ì¥ë“±ë¡: ì†¡ì¥íŒŒì¼(.xls/.xlsx) â†’ ë¼ì˜¤/ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´/ì¿ íŒ¡/ë– ë¦¬ëª° ë¶„ë¥˜ & ìƒì„±
# ======================================================================

# ì•ˆì „ ë¡œë” (.xls/.xlsx)
def _read_excel_any(file, header=0, dtype=str, keep_default_na=False) -> pd.DataFrame:
    """
    ì•ˆì „í•œ ì—‘ì…€ ë¡œë” (.xlsx/.xls)
      - ì—…ë¡œë“œ ë°”ì´íŠ¸ í™•ë³´ â†’ BytesIO ë¡œ ë§¤ ì‹œë„ë§ˆë‹¤ ìƒˆë¡œ ì½ìŒ
      - .xlsx â†’ openpyxl
      - .xls  â†’ xlrd (ê¶Œì¥ ë²„ì „: 1.2.0)
    """
    name = (getattr(file, "name", "") or "").lower()

    data = None
    if hasattr(file, "getvalue"):
        try:
            data = file.getvalue()
        except Exception:
            data = None
    if data is None:
        try:
            cur = file.tell() if hasattr(file, "tell") else None
            if hasattr(file, "seek"):
                file.seek(0)
            data = file.read()
            if hasattr(file, "seek") and cur is not None:
                file.seek(cur)
        except Exception:
            data = None

    def _read_with(engine: Optional[str]):
        bio = io.BytesIO(data) if data is not None else file
        return pd.read_excel(
            bio, sheet_name=0, header=header, dtype=dtype,
            keep_default_na=keep_default_na, engine=engine,
        )

    try:
        if name.endswith(".xlsx"):
            return _read_with("openpyxl")
        elif name.endswith(".xls"):
            try:
                return _read_with("xlrd")
            except Exception as e:
                raise RuntimeError(
                    "'.xls' íŒŒì¼ì„ ì½ìœ¼ë ¤ë©´ xlrdê°€ í•„ìš”í•©ë‹ˆë‹¤. ê¶Œì¥: pip install \"xlrd==1.2.0\"\n"
                    f"ì›ë³¸ ì˜¤ë¥˜: {e}"
                )
        else:
            try:
                return _read_with(None)
            except Exception:
                try:
                    return _read_with("openpyxl")
                except Exception:
                    try:
                        return _read_with("xlrd")
                    except Exception as e:
                        raise RuntimeError(
                            "ì—‘ì…€ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (.xlsxëŠ” openpyxl, .xlsëŠ” xlrd í•„ìš”)\n"
                            f"ì›ë³¸ ì˜¤ë¥˜: {e}"
                        )
    except RuntimeError:
        raise
    except Exception as e:
        raise RuntimeError(f"ì—‘ì…€ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")

# ìˆ«ìë§Œ ë‚¨ê¸°ëŠ” í—¬í¼ (ì¿ íŒ¡ ë§¤ì¹­ìš©)
def _digits_only(x: str) -> str:
    return re.sub(r"\D+", "", str(x or ""))

st.markdown("## ğŸšš ì†¡ì¥ë“±ë¡")

with st.expander("ë™ì‘ ìš”ì•½", expanded=False):
    st.markdown(
        """
        - **ë¶„ë¥˜ ê·œì¹™**
          1) ì£¼ë¬¸ë²ˆí˜¸ì— **`LO`** í¬í•¨ â†’ **ë¼ìŠ¤íŠ¸ì˜¤ë”(ë¼ì˜¤)**
          2) (ìˆ«ì ê¸°ì¤€) **16ìë¦¬** â†’ **ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´**
        - **ë¼ì˜¤ ì¶œë ¥**: í…œí”Œë¦¿ ì—…ë¡œë“œ ì—†ì´ ê³ ì • ì»¬ëŸ¼  
          **[`ì£¼ë¬¸ë²ˆí˜¸`, `íƒë°°ì‚¬ì½”ë“œ(08)`, `ì†¡ì¥ë²ˆí˜¸`]**
        - **ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì¶œë ¥**: ì£¼ë¬¸ íŒŒì¼ê³¼ **ì£¼ë¬¸ë²ˆí˜¸ ë§¤ì¹­** â†’ ì†¡ì¥ë²ˆí˜¸ ì¶”ê°€/ê°±ì‹   
          (ê²°ê³¼ **ì‹œíŠ¸ëª…: ë°œì†¡ì²˜ë¦¬**, `íƒë°°ì‚¬` ê¸°ë³¸ê°’=**ë¡¯ë°íƒë°°**, íŒŒì¼ëª…ì— íƒ€ì„ìŠ¤íƒ¬í”„)
        - **ì¿ íŒ¡ ì¶œë ¥**: **ì†¡ì¥íŒŒì¼ì˜ Pì—´(ì£¼ë¬¸ë²ˆí˜¸)** â†” **ì¿ íŒ¡ì£¼ë¬¸íŒŒì¼ì˜ Cì—´(ì£¼ë¬¸ë²ˆí˜¸)** ë¥¼  
          **ìˆ«ìë§Œ ë¹„êµ**í•˜ì—¬ ì¼ì¹˜ ì‹œ **ì¿ íŒ¡ì£¼ë¬¸íŒŒì¼ Eì—´(ìš´ì†¡ì¥ ë²ˆí˜¸)** ì— **ì†¡ì¥íŒŒì¼ì˜ ì†¡ì¥ë²ˆí˜¸** ì…ë ¥
        - **ë– ë¦¬ëª° ì¶œë ¥(í‚¤ì›Œë“œ)**: ë– ë¦¬ëª° ì£¼ë¬¸íŒŒì¼ì˜ **ì£¼ë¬¸ë²ˆí˜¸ ì»¬ëŸ¼**ì„ ì°¾ì•„ **ì†¡ì¥ë²ˆí˜¸**ë¥¼ ìë™ ê¸°ì…  
          (TRACKING_KEYS ì¤‘ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ì— ì“°ê³ , ì—†ìœ¼ë©´ `ì†¡ì¥ë²ˆí˜¸`ë¥¼ ìƒˆë¡œ ìƒì„±)
        """
    )

# ë¼ì˜¤ ê³ ì • ì»¬ëŸ¼
LAO_FIXED_TEMPLATE_COLUMNS = ["ì£¼ë¬¸ë²ˆí˜¸", "íƒë°°ì‚¬ì½”ë“œ", "ì†¡ì¥ë²ˆí˜¸"]

st.subheader("1) íŒŒì¼ ì—…ë¡œë“œ")
invoice_file = st.file_uploader("ì†¡ì¥ë²ˆí˜¸ í¬í•¨ íŒŒì¼ ì—…ë¡œë“œ (ì˜ˆ: ì†¡ì¥íŒŒì¼.xls)", type=["xls", "xlsx"], key="inv_file")
ss_order_file = st.file_uploader("ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì£¼ë¬¸ íŒŒì¼ ì—…ë¡œë“œ (ì„ íƒ)", type=["xlsx"], key="inv_ss_orders")
cp_order_file = st.file_uploader("ì¿ íŒ¡ ì£¼ë¬¸ íŒŒì¼ ì—…ë¡œë“œ (ì„ íƒ)", type=["xlsx"], key="inv_cp_orders")
tm_order_file = st.file_uploader("ë– ë¦¬ëª° ì£¼ë¬¸ íŒŒì¼ ì—…ë¡œë“œ (ì„ íƒ)", type=["xlsx"], key="inv_tm_orders")

run_invoice = st.button("ì†¡ì¥ë“±ë¡ ì‹¤í–‰")

# í—¤ë” í›„ë³´
ORDER_KEYS_INVOICE = ["ì£¼ë¬¸ë²ˆí˜¸", "ì£¼ë¬¸ID", "ì£¼ë¬¸ì½”ë“œ", "ì£¼ë¬¸ë²ˆí˜¸1"]
TRACKING_KEYS = ["ì†¡ì¥ë²ˆí˜¸", "ìš´ì†¡ì¥ë²ˆí˜¸", "ìš´ì†¡ì¥", "ë“±ê¸°ë²ˆí˜¸", "ìš´ì†¡ì¥ ë²ˆí˜¸", "ì†¡ì¥ë²ˆí˜¸1"]

SS_ORDER_KEYS = ["ì£¼ë¬¸ë²ˆí˜¸"]
SS_TRACKING_COL_NAME = "ì†¡ì¥ë²ˆí˜¸"

# ë– ë¦¬ëª° ì£¼ë¬¸íŒŒì¼ì—ì„œ ì£¼ë¬¸ë²ˆí˜¸ ì°¾ê¸° í›„ë³´
TM_ORDER_KEYS = ["ì£¼ë¬¸ë²ˆí˜¸", "ì£¼ë¬¸ID", "ì£¼ë¬¸ì½”ë“œ", "ì£¼ë¬¸ë²ˆí˜¸1"]

def build_order_tracking_map(df_invoice: pd.DataFrame):
    """ì†¡ì¥íŒŒì¼ì—ì„œ (ì£¼ë¬¸ë²ˆí˜¸ â†’ ì†¡ì¥ë²ˆí˜¸) ë§¤í•‘ ìƒì„± (í—¤ë”ëª… ê¸°ë°˜)"""
    order_col = find_col(ORDER_KEYS_INVOICE, df_invoice)
    tracking_col = find_col(TRACKING_KEYS, df_invoice)
    orders = df_invoice[order_col].astype(str)
    tracks = df_invoice[tracking_col].astype(str)
    orders = orders.where(orders.str.lower() != "nan", "")
    tracks = tracks.where(tracks.str.lower() != "nan", "")
    mapping = {}
    for o, t in zip(orders, tracks):
        if o and t:
            mapping[str(o)] = str(t)
    return mapping

def classify_orders(mapping: dict):
    """
    ë¶„ë¥˜:
      - ë¼ì˜¤: 'LO' í¬í•¨
      - ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´: ìˆ«ìë§Œ 16ìë¦¬
      (ì¿ íŒ¡ì€ ìë¦¬ìˆ˜ ë¬´ì‹œ ìˆ«ìë§¤ì¹­ìœ¼ë¡œ ë³„ë„ ì²˜ë¦¬)
    """
    lao, ss = {}, {}
    for o, t in mapping.items():
        s = str(o).strip()
        if "LO" in s.upper():
            lao[s] = t
        elif len(_digits_only(s)) == 16:
            ss[s] = t
    return lao, ss

def make_lao_invoice_df_fixed(lao_map: dict) -> pd.DataFrame:
    """ë¼ì˜¤ ì†¡ì¥: ê³ ì • ì»¬ëŸ¼ìœ¼ë¡œ DF ìƒì„± (íƒë°°ì‚¬ì½”ë“œ=08, ì»¬ëŸ¼ ìˆœì„œ ê³ ì •)"""
    if not lao_map:
        return pd.DataFrame(columns=LAO_FIXED_TEMPLATE_COLUMNS)
    orders = list(lao_map.keys())
    tracks = [lao_map[o] for o in orders]
    out = pd.DataFrame(
        {"ì£¼ë¬¸ë²ˆí˜¸": orders, "íƒë°°ì‚¬ì½”ë“œ": ["08"] * len(orders), "ì†¡ì¥ë²ˆí˜¸": tracks},
        columns=LAO_FIXED_TEMPLATE_COLUMNS,
    )
    return out

def make_ss_filled_df(ss_map: dict, ss_df: Optional[pd.DataFrame]) -> pd.DataFrame:
    """ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì£¼ë¬¸ íŒŒì¼ì— ì†¡ì¥ë²ˆí˜¸ë¥¼ ë§¤ì¹­í•´ ì¶”ê°€/ê°±ì‹  (íŒŒì¼ ì—†ìœ¼ë©´ 2ì—´ ë§¤í•‘ë§Œ)"""
    if ss_df is None or ss_df.empty:
        if not ss_map:
            return pd.DataFrame()
        df = pd.DataFrame({"ì£¼ë¬¸ë²ˆí˜¸": list(ss_map.keys()), SS_TRACKING_COL_NAME: list(ss_map.values())})
        df["íƒë°°ì‚¬"] = "ë¡¯ë°íƒë°°"
        return df

    col_order = find_col(SS_ORDER_KEYS, ss_df)
    out = ss_df.copy()
    if SS_TRACKING_COL_NAME not in out.columns:
        out[SS_TRACKING_COL_NAME] = ""

    existing = out[SS_TRACKING_COL_NAME].astype(str)
    is_empty = (existing.str.lower().eq("nan")) | (existing.str.strip().eq(""))
    mapped = out[col_order].astype(str).map(ss_map).fillna("")
    out.loc[is_empty, SS_TRACKING_COL_NAME] = mapped[is_empty]

    # íƒë°°ì‚¬ ê¸°ë³¸ê°’=ë¡¯ë°íƒë°°
    if "íƒë°°ì‚¬" not in out.columns:
        out["íƒë°°ì‚¬"] = "ë¡¯ë°íƒë°°"
    else:
        ser = out["íƒë°°ì‚¬"].astype(str)
        empty_mask = ser.str.lower().eq("nan") | ser.str.strip().eq("")
        out.loc[empty_mask, "íƒë°°ì‚¬"] = "ë¡¯ë°íƒë°°"

    return out

# --- (ì¿ íŒ¡) ì†¡ì¥íŒŒì¼ Pì—´ ê¸°ë°˜ ë§¤í•‘ ìƒì„±: í‚¤ëŠ” ìˆ«ìë§Œ ---
def build_inv_map_from_P(df_invoice: pd.DataFrame) -> dict:
    """
    ì†¡ì¥íŒŒì¼: Pì—´(ì£¼ë¬¸ë²ˆí˜¸) â†” ì†¡ì¥ë²ˆí˜¸(ì—¬ëŸ¬ í—¤ë”ëª… ì¤‘ íƒìƒ‰) â†’ {ìˆ«ìí‚¤: ì†¡ì¥ë²ˆí˜¸}
    """
    inv_cols = list(df_invoice.columns)
    try:
        inv_order_col = inv_cols[excel_col_to_index("P")]
    except Exception:
        raise RuntimeError("ì†¡ì¥íŒŒì¼ì— Pì—´(ì£¼ë¬¸ë²ˆí˜¸)ì´ ì—†ìŠµë‹ˆë‹¤. ì†¡ì¥íŒŒì¼ ì–‘ì‹ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    tracking_col = find_col(TRACKING_KEYS, df_invoice)

    orders = df_invoice[inv_order_col].astype(str).where(lambda s: s.str.lower() != "nan", "")
    tracks = df_invoice[tracking_col].astype(str).where(lambda s: s.str.lower() != "nan", "")

    inv_map = {}
    for o, t in zip(orders, tracks):
        key = _digits_only(o)
        if key and str(t):
            inv_map[key] = str(t)  # ì¤‘ë³µ í‚¤ëŠ” ë§ˆì§€ë§‰ ê°’ ìš°ì„ 
    return inv_map

def make_cp_filled_df_by_letters(df_invoice: Optional[pd.DataFrame],
                                 cp_df: Optional[pd.DataFrame]) -> pd.DataFrame:
    """
    ì¿ íŒ¡ ì†¡ì¥ë“±ë¡:
      - ë§¤ì¹­ í‚¤: (ìˆ«ìë§Œ ë‚¨ê¸´) ì†¡ì¥íŒŒì¼ì˜ Pì—´ ì£¼ë¬¸ë²ˆí˜¸ â†” (ìˆ«ìë§Œ ë‚¨ê¸´) ì¿ íŒ¡ì£¼ë¬¸íŒŒì¼ì˜ Cì—´ ì£¼ë¬¸ë²ˆí˜¸
      - ì“°ê¸° ëŒ€ìƒ: ì¿ íŒ¡ì£¼ë¬¸íŒŒì¼ì˜ Eì—´(ìš´ì†¡ì¥ ë²ˆí˜¸) â† ì†¡ì¥íŒŒì¼ì˜ 'ì†¡ì¥ë²ˆí˜¸'
      - ìë¦¬ìˆ˜/í¬ë§· ë¬´ì‹œ(ìˆ«ìë§Œ ë¹„êµ)
    """
    if cp_df is None or cp_df.empty:
        return pd.DataFrame()
    if df_invoice is None or df_invoice.empty:
        return cp_df

    inv_map = build_inv_map_from_P(df_invoice)

    cp_cols = list(cp_df.columns)
    try:
        cp_order_col = cp_cols[excel_col_to_index("C")]  # ë§¤ì¹­ í‚¤
    except Exception:
        raise RuntimeError("ì¿ íŒ¡ ì£¼ë¬¸ íŒŒì¼ì— Cì—´(ì£¼ë¬¸ë²ˆí˜¸)ì´ ì—†ìŠµë‹ˆë‹¤. ì¿ íŒ¡ ì£¼ë¬¸íŒŒì¼ ì–‘ì‹ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    try:
        cp_track_col = cp_cols[excel_col_to_index("E")]  # ì“°ê¸° ëŒ€ìƒ
    except Exception:
        cp_track_col = "ìš´ì†¡ì¥ ë²ˆí˜¸"
        if cp_track_col not in cp_df.columns:
            cp_df = cp_df.copy()
            cp_df[cp_track_col] = ""
        cp_cols = list(cp_df.columns)

    out = cp_df.copy()
    cp_keys = out[cp_order_col].astype(str).map(_digits_only)
    mapped = cp_keys.map(inv_map)

    mask = mapped.notna() & mapped.astype(str).str.len().gt(0)
    out.loc[mask, cp_track_col] = mapped[mask]

    return out

def make_tm_filled_df(tm_df: Optional[pd.DataFrame], inv_map: dict) -> pd.DataFrame:
    """
    ë– ë¦¬ëª° ì†¡ì¥ë“±ë¡(í‚¤ì›Œë“œ):
      - ë§¤ì¹­ í‚¤: ë– ë¦¬ëª° ì£¼ë¬¸íŒŒì¼ì˜ 'ì£¼ë¬¸ë²ˆí˜¸' (í—¤ë” í‚¤ì›Œë“œ íƒìƒ‰)
      - ì“°ê¸° ëŒ€ìƒ: ë– ë¦¬ëª° ì£¼ë¬¸íŒŒì¼ì˜ ì†¡ì¥ ì»¬ëŸ¼ (TRACKING_KEYS ì¤‘ ì¡´ì¬í•˜ëŠ” ì²« ì»¬ëŸ¼, ì—†ìœ¼ë©´ 'ì†¡ì¥ë²ˆí˜¸' ìƒì„±)
      - ë¹„êµ ë°©ì‹: ë¬¸ìì—´ ê·¸ëŒ€ë¡œ ë§¤ì¹­
    """
    if tm_df is None or tm_df.empty:
        return pd.DataFrame()

    # 1) ì£¼ë¬¸ë²ˆí˜¸ ì»¬ëŸ¼ ì°¾ê¸°
    tm_order_col = find_col(TM_ORDER_KEYS, tm_df)

    # 2) ì†¡ì¥ë²ˆí˜¸(ê¸°ì…) ì»¬ëŸ¼ ê²°ì •
    tracking_col_candidates = [c for c in TRACKING_KEYS if c in list(tm_df.columns)]
    if tracking_col_candidates:
        tm_tracking_col = tracking_col_candidates[0]
        out = tm_df.copy()
    else:
        tm_tracking_col = "ì†¡ì¥ë²ˆí˜¸"
        out = tm_df.copy()
        if tm_tracking_col not in out.columns:
            out[tm_tracking_col] = ""

    # 3) ë§¤í•‘ ì ìš©
    keys = out[tm_order_col].astype(str)
    mapped = keys.map(inv_map)

    mask = mapped.notna() & mapped.astype(str).str.len().gt(0)
    out.loc[mask, tm_tracking_col] = mapped[mask]

    return out

if run_invoice:
    df_invoice = None
    df_ss_orders = None
    df_cp_orders = None
    df_tm_orders = None

    if not invoice_file:
        st.error("ì†¡ì¥ë²ˆí˜¸ê°€ í¬í•¨ëœ ì†¡ì¥íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. (ì˜ˆ: ì†¡ì¥íŒŒì¼.xls)")
    else:
        try:
            df_invoice = _read_excel_any(invoice_file, header=0, dtype=str, keep_default_na=False)
        except Exception as e:
            st.exception(RuntimeError(f"ì†¡ì¥íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}"))
            df_invoice = None

        if ss_order_file:
            try:
                df_ss_orders = read_first_sheet_source_as_text(ss_order_file)
            except Exception as e:
                st.warning(f"ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì£¼ë¬¸ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜: {e}")
                df_ss_orders = None

        if cp_order_file:
            try:
                df_cp_orders = read_first_sheet_source_as_text(cp_order_file)
            except Exception as e:
                st.warning(f"ì¿ íŒ¡ ì£¼ë¬¸ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜: {e}")
                df_cp_orders = None

        if tm_order_file:
            try:
                df_tm_orders = read_first_sheet_source_as_text(tm_order_file)
            except Exception as e:
                st.warning(f"ë– ë¦¬ëª° ì£¼ë¬¸ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜: {e}")
                df_tm_orders = None

        if df_invoice is None:
            st.error("ì†¡ì¥íŒŒì¼ì„ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ ë° ë‚´ìš©(ì£¼ë¬¸ë²ˆí˜¸/ì†¡ì¥ë²ˆí˜¸ ì»¬ëŸ¼)ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        else:
            try:
                order_track_map = build_order_tracking_map(df_invoice)
                lao_map, ss_map = classify_orders(order_track_map)

                lao_out_df = make_lao_invoice_df_fixed(lao_map)
                ss_out_df = make_ss_filled_df(ss_map, df_ss_orders)
                cp_out_df = make_cp_filled_df_by_letters(df_invoice, df_cp_orders)
                tm_out_df = make_tm_filled_df(df_tm_orders, order_track_map)

                cp_update_cnt = 0
                if df_cp_orders is not None and not df_cp_orders.empty:
                    try:
                        inv_map_tmp = build_inv_map_from_P(df_invoice)
                        cp_cols_tmp = list(df_cp_orders.columns)
                        cp_order_col_tmp = cp_cols_tmp[excel_col_to_index("C")]
                        mapped_tmp = df_cp_orders[cp_order_col_tmp].astype(str).map(_digits_only).map(inv_map_tmp)
                        cp_update_cnt = int((mapped_tmp.notna() & mapped_tmp.astype(str).str.len().gt(0)).sum())
                    except Exception:
                        cp_update_cnt = 0

                # ë– ë¦¬ëª° ì—…ë°ì´íŠ¸ ê±´ìˆ˜ ì¶”ì •
                tm_update_cnt = 0
                if df_tm_orders is not None and not df_tm_orders.empty and tm_out_df is not None and not tm_out_df.empty:
                    try:
                        tm_track_col = next((c for c in TRACKING_KEYS if c in tm_out_df.columns), "ì†¡ì¥ë²ˆí˜¸")
                        before = df_tm_orders.get(tm_track_col, pd.Series([""]*len(df_tm_orders))).astype(str).fillna("")
                        after  = tm_out_df.get(tm_track_col, pd.Series([""]*len(tm_out_df))).astype(str).fillna("")
                        tm_update_cnt = int((before != after).sum())
                    except Exception:
                        tm_update_cnt = 0

                st.success(
                    f"ë¶„ë¥˜/ë§¤ì¹­ ì™„ë£Œ: ë¼ì˜¤ {len(lao_map)}ê±´ / ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ {len(ss_map)}ê±´ / "
                    f"ì¿ íŒ¡ ì—…ë°ì´íŠ¸ ì˜ˆì • {cp_update_cnt}ê±´ / ë– ë¦¬ëª° ê°±ì‹  {tm_update_cnt}ê±´"
                )
                with st.expander("ë¼ì˜¤ ì†¡ì¥ ë¯¸ë¦¬ë³´ê¸°", expanded=True):
                    st.dataframe(lao_out_df.head(50))
                with st.expander("ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì†¡ì¥ ë¯¸ë¦¬ë³´ê¸° (ì‹œíŠ¸ëª…: ë°œì†¡ì²˜ë¦¬)", expanded=False):
                    st.dataframe(ss_out_df.head(50))
                with st.expander("ì¿ íŒ¡ ì†¡ì¥ ë¯¸ë¦¬ë³´ê¸°", expanded=False):
                    st.dataframe(cp_out_df.head(50))
                with st.expander("ë– ë¦¬ëª° ì†¡ì¥ ë¯¸ë¦¬ë³´ê¸°", expanded=False):
                    st.dataframe(tm_out_df.head(50))

                # ë‹¤ìš´ë¡œë“œ(í˜•ì‹ ì„ íƒ)
                download_df(lao_out_df, "ë¼ì˜¤ ì†¡ì¥ ì™„ì„± ë‹¤ìš´ë¡œë“œ", "ë¼ì˜¤ ì†¡ì¥ ì™„ì„±", "lao_inv")
                if ss_out_df is not None and not ss_out_df.empty:
                    ss_out_export = ss_out_df.copy()
                    if "íƒë°°ì‚¬" not in ss_out_export.columns:
                        ss_out_export["íƒë°°ì‚¬"] = "ë¡¯ë°íƒë°°"
                    else:
                        ser = ss_out_export["íƒë°°ì‚¬"].astype(str)
                        empty_mask = ser.str.lower().eq("nan") | ser.str.strip().eq("")
                        ss_out_export.loc[empty_mask, "íƒë°°ì‚¬"] = "ë¡¯ë°íƒë°°"
                    download_df(
                        ss_out_export,
                        "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì†¡ì¥ ì™„ì„± ë‹¤ìš´ë¡œë“œ",
                        "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì†¡ì¥ ì™„ì„±",
                        "ss_inv",
                        sheet_name="ë°œì†¡ì²˜ë¦¬",      # â˜… ì‹œíŠ¸ëª… ê³ ì •
                        csv_sep_override=",",       # â˜… CSV ì‰¼í‘œ ê³ ì •
                        csv_encoding_override=None,
                    )
                if cp_out_df is not None and not cp_out_df.empty:
                    download_df(cp_out_df, "ì¿ íŒ¡ ì†¡ì¥ ì™„ì„± ë‹¤ìš´ë¡œë“œ", "ì¿ íŒ¡ ì†¡ì¥ ì™„ì„±", "cp_inv")
                if tm_out_df is not None and not tm_out_df.empty:
                    download_df(tm_out_df, "ë– ë¦¬ëª° ì†¡ì¥ ì™„ì„± ë‹¤ìš´ë¡œë“œ", "ë– ë¦¬ëª° ì†¡ì¥ ì™„ì„±", "tm_inv")

                if (ss_out_df is None or ss_out_df.empty) and (cp_out_df is None or cp_out_df.empty) and (tm_out_df is None or tm_out_df.empty):
                    st.info("ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´/ì¿ íŒ¡/ë– ë¦¬ëª° ëŒ€ìƒ ê±´ì´ ì—†ê±°ë‚˜, ë§¤ì¹­í•  ì£¼ë¬¸ íŒŒì¼ì´ ì—†ì–´ ìƒì„± ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

            except Exception as e:
                st.exception(RuntimeError(f"ì†¡ì¥ë“±ë¡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}"))
